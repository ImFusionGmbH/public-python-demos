{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Manipulating Images"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-09-18T12:31:04.243997Z",
     "start_time": "2024-09-18T12:31:01.900296Z"
    }
   },
   "source": [
    "import imfusion\n",
    "import numpy as np\n",
    "from copy import deepcopy\n",
    "\n",
    "from imfusion_sdk.demo_utils import mpr_plot, unzip_folder\n",
    "\n",
    "unzipped_folder = unzip_folder('data/pet-ct-rtstruct.zip')"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Public beta build of ImFusion Python SDK. Not for commercial use.\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Orientation and size of the image in the physical world\n",
    "- Pixel Space: the grid where the voxels are indexed (`i` in `[0, Width]`, `j` in `[0, Heigth]`, `k` in `[0, Slices]`).\n",
    "- Image Space: Voxel grid in metric units (mm), with center of the image defined as `O = (x, y, z) = (0, 0, 0)`.\n",
    "The size of a voxel is defined by the `spacing`. Image coordinates take values `x` in `[-SizeX / 2, SizeX / 2]`, `y` in `[-SizeY / 2, SizeY / 2]`, `x` in `[-SizeZ / 2, SizeZ / 2]`.\n",
    "- World Space: Every SharedImage contains a `matrix` which describes the orientation of the voxel array in the physical world. The `matrix` specifies the transformation from the image space to the physical world.\n",
    "\n",
    "![Coordinate Systems](images/CoordinateSystems.png)"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-09-18T12:31:04.425385Z",
     "start_time": "2024-09-18T12:31:04.246753Z"
    }
   },
   "source": [
    "pet_sis, *_ = imfusion.load('data/pet-ct-rtstruct/pet')\n",
    "pet_image = pet_sis[0]\n",
    "\n",
    "np.set_printoptions(suppress=True)\n",
    "\n",
    "print('Image matrix:\\n', pet_image.matrix) # matrix from world\n",
    "print('Image spacing:', pet_image.descriptor.spacing)\n",
    "print('Image dimensions:', pet_image.descriptor.dimensions)\n",
    "print('Image extent:', pet_image.descriptor.extent)\n",
    "print('Image coordinate of Voxel (0, 0, 0)', pet_image.descriptor.pixel_to_image([0, 0, 0]))\n",
    "print('Voxel coordinate of Image Center (0., 0., 0.)', pet_image.descriptor.image_to_pixel([0., 0., 0.]))\n",
    "\n",
    "# get world position of Voxel (0, 0, 0):\n",
    "print(f'World coordinate (aka Position) of Voxel (0, 0, 0): {pet_image.descriptor_world.pixel_to_world([0, 0, 0])}')\n",
    "print(f'World coordinate of Image Center (0., 0., 0.): {np.matmul(pet_image.descriptor_world.matrix_to_world, np.array([0., 0., 0., 1.]))}')"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Core.Filesystem.Path] No such file or directory\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "Could not open file '../data/pet-ct-rtstruct/pet'",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mFileNotFoundError\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[2], line 1\u001B[0m\n\u001B[0;32m----> 1\u001B[0m pet_sis, \u001B[38;5;241m*\u001B[39m_ \u001B[38;5;241m=\u001B[39m \u001B[43mimfusion\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mload\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43m../data/pet-ct-rtstruct/pet\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[1;32m      2\u001B[0m pet_image \u001B[38;5;241m=\u001B[39m pet_sis[\u001B[38;5;241m0\u001B[39m]\n\u001B[1;32m      4\u001B[0m np\u001B[38;5;241m.\u001B[39mset_printoptions(suppress\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m)\n",
      "\u001B[0;31mFileNotFoundError\u001B[0m: Could not open file '../data/pet-ct-rtstruct/pet'"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Algorithms of the ImFusion SDK take the orientation and spacing information into account.\n",
    "\n",
    "If we resample the image to a spacing of 2 mm in each dimension, the information in the SharedImage is also updated automatically:"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "print(\"before:\\t\", pet_sis[0].descriptor)\n",
    "\n",
    "resample_algo = imfusion.ImageResamplingAlgorithm(pet_sis)\n",
    "# Create new image or resample image in ctor in places\n",
    "resample_algo.create_new_image = True\n",
    "# Resampling mode, can be a spacing, a percentage, a dimension, a binning..\n",
    "resample_algo.resampling_mode = imfusion.ImageResamplingAlgorithm.ResamplingMode.TARGET_SPACING\n",
    "# Reduction can be Lookup, Average, Min, Max\n",
    "resample_algo.reduction_mode = imfusion.ReductionMode.AVERAGE\n",
    "# Interpolation can be nearest, linear or bicubic\n",
    "resample_algo.interpolation_mode = imfusion.InterpolationMode.LINEAR\n",
    "resample_algo.target_spacing = [2., 2., 2.] # mm\n",
    "resample_algo.compute()\n",
    "(resampled_pet,) = resample_algo.output()\n",
    "\n",
    "imfusion.save([resampled_pet], '../data/resampled_pet.imf')\n",
    "\n",
    "print(\"after:\\t\", resampled_pet[0].descriptor)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "We can also resample based on geometric descriptor of another image.\n",
    "\n",
    "Since the SharedImages contain the orientation and spacing information, we can easily resample using a reference image.\n",
    "\n",
    "To leverage that, the ResampleImageAlgorithm can be used with two input: the image to resample and a reference image."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "(ct_sis,) = imfusion.load('data/pet-ct-rtstruct/ct.imf')\n",
    "\n",
    "print(f'original CT: {ct_sis[0].descriptor}\\n')\n",
    "\n",
    "resample_algo = imfusion.ImageResamplingAlgorithm(ct_sis, resampled_pet)\n",
    "resample_algo.create_new_image = True\n",
    "resample_algo.compute()\n",
    "(resampled_ct,) = resample_algo.output()\n",
    "imfusion.save([resampled_ct], '../data/resampled_ct.imf')\n",
    "\n",
    "\n",
    "print(f'CT: {resampled_ct[0].descriptor}')\n",
    "print(f'PET: {resampled_pet[0].descriptor}')"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Advanced use of ImageResamplingAlgorithm "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since we actually need just geometric information, it is possible to use the image resampling algorithm to create a well defined crop/pad of the image by solely specifying a geometric descriptor"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "new_descriptor_world = pet_sis[0].descriptor_world\n",
    "# We want to crop/pad at the current center of the image, thus we leave the \n",
    "# translation part of the affine matrix untouched, while setting to Identity the \n",
    "# rotation part\n",
    "original_matrix = deepcopy(new_descriptor_world.matrix_to_world)\n",
    "original_matrix[:3, :3] = np.eye(3)\n",
    "new_descriptor_world.matrix_to_world = original_matrix\n",
    "\n",
    "# Adjust the dimensions and the pixel spacing.\n",
    "# The resulting image will have an isotropic extent of 12.8 cm\n",
    "new_descriptor_world.descriptor.spacing = [1.5, 1.5, 1.5]\n",
    "new_descriptor_world.descriptor.dimensions = [160, 160, 160]\n",
    "\n",
    "resample = imfusion.ImageResamplingAlgorithm(pet_sis, [new_descriptor_world])\n",
    "resample.create_new_image = True\n",
    "resample.resampling_mode = imfusion.ImageResamplingAlgorithm.ResamplingMode.TARGET_PERCENT\n",
    "resample.reduction_mode = imfusion.ReductionMode.AVERAGE\n",
    "resample.interpolation_mode = imfusion.InterpolationMode.LINEAR\n",
    "resample.compute()\n",
    "\n",
    "cropped_pet = resample.output()[0]\n",
    "\n",
    "print(cropped_pet)\n",
    "\n",
    "imfusion.save([cropped_pet], '../data/cropped_pet.imf')\n",
    "\n",
    "print(\"Original:\")\n",
    "mpr_plot(pet_sis[0])\n",
    "print(\"Cropped:\")\n",
    "mpr_plot(cropped_pet[0])\n",
    "None"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
